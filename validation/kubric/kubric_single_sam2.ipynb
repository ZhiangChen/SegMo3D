{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic SfM: single scene on synthetic data generated from Kubric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Generate synthetic data\n",
    "We developed a tool to generate synthetic data using Kubric. Please follow the instructions on the Github repo: https://github.com/ZhiangChen/data_generator_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Organize data\n",
    "Create a folder under `semantic_SfM/data` and organize your data following the structures below. \n",
    "\n",
    "```\n",
    "semantic_SfM/data\n",
    "    ├── kubric_0\n",
    "        ├── photos\n",
    "        │       ├── 0.png\n",
    "        │       ├── 1.png\n",
    "        │       ├── ...\n",
    "        │       └── 323.png\n",
    "        ├── reconstructions\n",
    "        │       ├── camera_poses.npy\n",
    "        │       └── combined_point_cloud.las   \n",
    "        ├── segmentations_gt\n",
    "        │       ├── 0.npy\n",
    "        │       ├── 0.png\n",
    "        │       └── ...\n",
    "        └── associations\n",
    "                └── depth\n",
    "                        ├── 0.npy\n",
    "                        ├── 0.png\n",
    "                        └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "scene_dir = '../../data/kubric_1'\n",
    "pointcloud_path = os.path.join(scene_dir, 'reconstructions', 'combined_point_cloud.las')\n",
    "associations_folder_path = os.path.join(scene_dir, 'associations')\n",
    "segmentations_folder_path = os.path.join(scene_dir, 'segmentations')\n",
    "photos_folder_path = os.path.join(scene_dir, 'photos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Segment images using SAM \n",
    "\n",
    "#### 2a. SAM segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.image_segmentation import ImageSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_params = {}\n",
    "sam_params['model_name'] = 'sam2'\n",
    "sam_params['model_path'] = '../../semantic_SfM/sam2/sam2.1_hiera_large.pt'\n",
    "sam_params['device'] = 'cuda:1'\n",
    "sam_params['points_per_side'] = 32\n",
    "sam_params['points_per_batch'] = 128\n",
    "sam_params['pred_iou_thresh'] = 0.6\n",
    "sam_params['stability_score_offset'] = 0.5\n",
    "sam_params['box_nms_thresh'] = 0.6\n",
    "sam_params['use_m2m'] = True\n",
    "\n",
    "\n",
    "image_paths = [os.path.join(scene_dir, 'photos', image) for image in os.listdir(os.path.join(scene_dir, 'photos'))]\n",
    "\n",
    "# sort images based on the values of keyimages in file names\n",
    "image_paths = sorted(image_paths, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/285.\n",
      "Processing image 2/285.\n",
      "Processing image 3/285.\n",
      "Processing image 4/285.\n",
      "Processing image 5/285.\n",
      "Processing image 6/285.\n",
      "Processing image 7/285.\n",
      "Processing image 8/285.\n",
      "Processing image 9/285.\n",
      "Processing image 10/285.\n",
      "Processing image 11/285.\n",
      "Processing image 12/285.\n",
      "Processing image 13/285.\n",
      "Processing image 14/285.\n",
      "Processing image 15/285.\n",
      "Processing image 16/285.\n",
      "Processing image 17/285.\n",
      "Processing image 18/285.\n",
      "Processing image 19/285.\n",
      "Processing image 20/285.\n",
      "Processing image 21/285.\n",
      "Processing image 22/285.\n",
      "Processing image 23/285.\n",
      "Processing image 24/285.\n",
      "Processing image 25/285.\n",
      "Processing image 26/285.\n",
      "Processing image 27/285.\n",
      "Processing image 28/285.\n",
      "Processing image 29/285.\n",
      "Processing image 30/285.\n",
      "Processing image 31/285.\n",
      "Processing image 32/285.\n",
      "Processing image 33/285.\n",
      "Processing image 34/285.\n",
      "Processing image 35/285.\n",
      "Processing image 36/285.\n",
      "Processing image 37/285.\n",
      "Processing image 38/285.\n",
      "Processing image 39/285.\n",
      "Processing image 40/285.\n",
      "Processing image 41/285.\n",
      "Processing image 42/285.\n",
      "Processing image 43/285.\n",
      "Processing image 44/285.\n",
      "Processing image 45/285.\n",
      "Processing image 46/285.\n",
      "Processing image 47/285.\n",
      "Processing image 48/285.\n",
      "Processing image 49/285.\n",
      "Processing image 50/285.\n",
      "Processing image 51/285.\n",
      "Processing image 52/285.\n",
      "Processing image 53/285.\n",
      "Processing image 54/285.\n",
      "Processing image 55/285.\n",
      "Processing image 56/285.\n",
      "Processing image 57/285.\n",
      "Processing image 58/285.\n",
      "Processing image 59/285.\n",
      "Processing image 60/285.\n",
      "Processing image 61/285.\n",
      "Processing image 62/285.\n",
      "Processing image 63/285.\n",
      "Processing image 64/285.\n",
      "Processing image 65/285.\n",
      "Processing image 66/285.\n",
      "Processing image 67/285.\n",
      "Processing image 68/285.\n",
      "Processing image 69/285.\n",
      "Processing image 70/285.\n",
      "Processing image 71/285.\n",
      "Processing image 72/285.\n",
      "Processing image 73/285.\n",
      "Processing image 74/285.\n",
      "Processing image 75/285.\n",
      "Processing image 76/285.\n",
      "Processing image 77/285.\n",
      "Processing image 78/285.\n",
      "Processing image 79/285.\n",
      "Processing image 80/285.\n",
      "Processing image 81/285.\n",
      "Processing image 82/285.\n",
      "Processing image 83/285.\n",
      "Processing image 84/285.\n",
      "Processing image 85/285.\n",
      "Processing image 86/285.\n",
      "Processing image 87/285.\n",
      "Processing image 88/285.\n",
      "Processing image 89/285.\n",
      "Processing image 90/285.\n",
      "Processing image 91/285.\n",
      "Processing image 92/285.\n",
      "Processing image 93/285.\n",
      "Processing image 94/285.\n",
      "Processing image 95/285.\n",
      "Processing image 96/285.\n",
      "Processing image 97/285.\n",
      "Processing image 98/285.\n",
      "Processing image 99/285.\n",
      "Processing image 100/285.\n",
      "Processing image 101/285.\n",
      "Processing image 102/285.\n",
      "Processing image 103/285.\n",
      "Processing image 104/285.\n",
      "Processing image 105/285.\n",
      "Processing image 106/285.\n",
      "Processing image 107/285.\n",
      "Processing image 108/285.\n",
      "Processing image 109/285.\n",
      "Processing image 110/285.\n",
      "Processing image 111/285.\n",
      "Processing image 112/285.\n",
      "Processing image 113/285.\n",
      "Processing image 114/285.\n",
      "Processing image 115/285.\n",
      "Processing image 116/285.\n",
      "Processing image 117/285.\n",
      "Processing image 118/285.\n",
      "Processing image 119/285.\n",
      "Processing image 120/285.\n",
      "Processing image 121/285.\n",
      "Processing image 122/285.\n",
      "Processing image 123/285.\n",
      "Processing image 124/285.\n",
      "Processing image 125/285.\n",
      "Processing image 126/285.\n",
      "Processing image 127/285.\n",
      "Processing image 128/285.\n",
      "Processing image 129/285.\n",
      "Processing image 130/285.\n",
      "Processing image 131/285.\n",
      "Processing image 132/285.\n",
      "Processing image 133/285.\n",
      "Processing image 134/285.\n",
      "Processing image 135/285.\n",
      "Processing image 136/285.\n",
      "Processing image 137/285.\n",
      "Processing image 138/285.\n",
      "Processing image 139/285.\n",
      "Processing image 140/285.\n",
      "Processing image 141/285.\n",
      "Processing image 142/285.\n",
      "Processing image 143/285.\n",
      "Processing image 144/285.\n",
      "Processing image 145/285.\n",
      "Processing image 146/285.\n",
      "Processing image 147/285.\n",
      "Processing image 148/285.\n",
      "Processing image 149/285.\n",
      "Processing image 150/285.\n",
      "Processing image 151/285.\n",
      "Processing image 152/285.\n",
      "Processing image 153/285.\n",
      "Processing image 154/285.\n",
      "Processing image 155/285.\n",
      "Processing image 156/285.\n",
      "Processing image 157/285.\n",
      "Processing image 158/285.\n",
      "Processing image 159/285.\n",
      "Processing image 160/285.\n",
      "Processing image 161/285.\n",
      "Processing image 162/285.\n",
      "Processing image 163/285.\n",
      "Processing image 164/285.\n",
      "Processing image 165/285.\n",
      "Processing image 166/285.\n",
      "Processing image 167/285.\n",
      "Processing image 168/285.\n",
      "Processing image 169/285.\n",
      "Processing image 170/285.\n",
      "Processing image 171/285.\n",
      "Processing image 172/285.\n",
      "Processing image 173/285.\n",
      "Processing image 174/285.\n",
      "Processing image 175/285.\n",
      "Processing image 176/285.\n",
      "Processing image 177/285.\n",
      "Processing image 178/285.\n",
      "Processing image 179/285.\n",
      "Processing image 180/285.\n",
      "Processing image 181/285.\n",
      "Processing image 182/285.\n",
      "Processing image 183/285.\n",
      "Processing image 184/285.\n",
      "Processing image 185/285.\n",
      "Processing image 186/285.\n",
      "Processing image 187/285.\n",
      "Processing image 188/285.\n",
      "Processing image 189/285.\n",
      "Processing image 190/285.\n",
      "Processing image 191/285.\n",
      "Processing image 192/285.\n",
      "Processing image 193/285.\n",
      "Processing image 194/285.\n",
      "Processing image 195/285.\n",
      "Processing image 196/285.\n",
      "Processing image 197/285.\n",
      "Processing image 198/285.\n",
      "Processing image 199/285.\n",
      "Processing image 200/285.\n",
      "Processing image 201/285.\n",
      "Processing image 202/285.\n",
      "Processing image 203/285.\n",
      "Processing image 204/285.\n",
      "Processing image 205/285.\n",
      "Processing image 206/285.\n",
      "Processing image 207/285.\n",
      "Processing image 208/285.\n",
      "Processing image 209/285.\n",
      "Processing image 210/285.\n",
      "Processing image 211/285.\n",
      "Processing image 212/285.\n",
      "Processing image 213/285.\n",
      "Processing image 214/285.\n",
      "Processing image 215/285.\n",
      "Processing image 216/285.\n",
      "Processing image 217/285.\n",
      "Processing image 218/285.\n",
      "Processing image 219/285.\n",
      "Processing image 220/285.\n",
      "Processing image 221/285.\n",
      "Processing image 222/285.\n",
      "Processing image 223/285.\n",
      "Processing image 224/285.\n",
      "Processing image 225/285.\n",
      "Processing image 226/285.\n",
      "Processing image 227/285.\n",
      "Processing image 228/285.\n",
      "Processing image 229/285.\n",
      "Processing image 230/285.\n",
      "Processing image 231/285.\n",
      "Processing image 232/285.\n",
      "Processing image 233/285.\n",
      "Processing image 234/285.\n",
      "Processing image 235/285.\n",
      "Processing image 236/285.\n",
      "Processing image 237/285.\n",
      "Processing image 238/285.\n",
      "Processing image 239/285.\n",
      "Processing image 240/285.\n",
      "Processing image 241/285.\n",
      "Processing image 242/285.\n",
      "Processing image 243/285.\n",
      "Processing image 244/285.\n",
      "Processing image 245/285.\n",
      "Processing image 246/285.\n",
      "Processing image 247/285.\n",
      "Processing image 248/285.\n",
      "Processing image 249/285.\n",
      "Processing image 250/285.\n",
      "Processing image 251/285.\n",
      "Processing image 252/285.\n",
      "Processing image 253/285.\n",
      "Processing image 254/285.\n",
      "Processing image 255/285.\n",
      "Processing image 256/285.\n",
      "Processing image 257/285.\n",
      "Processing image 258/285.\n",
      "Processing image 259/285.\n",
      "Processing image 260/285.\n",
      "Processing image 261/285.\n",
      "Processing image 262/285.\n",
      "Processing image 263/285.\n",
      "Processing image 264/285.\n",
      "Processing image 265/285.\n",
      "Processing image 266/285.\n",
      "Processing image 267/285.\n",
      "Processing image 268/285.\n",
      "Processing image 269/285.\n",
      "Processing image 270/285.\n",
      "Processing image 271/285.\n",
      "Processing image 272/285.\n",
      "Processing image 273/285.\n",
      "Processing image 274/285.\n",
      "Processing image 275/285.\n",
      "Processing image 276/285.\n",
      "Processing image 277/285.\n",
      "Processing image 278/285.\n",
      "Processing image 279/285.\n",
      "Processing image 280/285.\n",
      "Processing image 281/285.\n",
      "Processing image 282/285.\n",
      "Processing image 283/285.\n",
      "Processing image 284/285.\n",
      "Processing image 285/285.\n"
     ]
    }
   ],
   "source": [
    "run_segmentation = False\n",
    "\n",
    "if run_segmentation:\n",
    "    image_segmentor = ImageSegmentation(sam_params)   \n",
    "    image_segmentor.batch_predict(image_paths, segmentations_folder_path, save_overlap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Mask filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.simple_mask_filter import AreaFilter\n",
    "area_filter = AreaFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:06<00:00, 45.04it/s]\n"
     ]
    }
   ],
   "source": [
    "segmentations_folder_path = os.path.join(scene_dir, 'segmentations_filtered')\n",
    "\n",
    "config = {'area_lower_threshold': 100,\n",
    "'segmentation_folder_path': '../../data/kubric_1/segmentations',\n",
    "'output_folder_path': segmentations_folder_path,\n",
    "'num_processes':8}\n",
    "\n",
    "area_filter(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create projection associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.probabilistic_projection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud_projector = PointcloudProjection(depth_filtering_threshold=1.8)\n",
    "pointcloud_projector.read_kubric_camera_parameters(scene_dir)\n",
    "pointcloud_projector.read_pointcloud(pointcloud_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image list\n",
    "photo_folder_path = os.path.join(scene_dir, 'photos')\n",
    "image_list = [f for f in os.listdir(photo_folder_path) if f.endswith('.png')]\n",
    "# sort image list based on the number in the file name\n",
    "image_list.sort(key=lambda x: int(x.split('/')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 285/285 [00:16<00:00, 17.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#pointcloud_projector.parallel_batch_project(image_list, save_folder_path)\n",
    "pointcloud_projector.parallel_batch_project_joblib(image_list, associations_folder_path, num_workers=16, save_depth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keyimage associations\n",
    "from ssfm.keyimage_associations_builder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kubric_1/associations\n",
      "../../data/kubric_1/segmentations_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:01<00:00, 199.67it/s]\n"
     ]
    }
   ],
   "source": [
    "print(associations_folder_path)\n",
    "print(segmentations_folder_path)\n",
    "smc_solver = KeyimageAssociationsBuilder(associations_folder_path, segmentations_folder_path)\n",
    "smc_solver.build_associations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric                                                       | Count      | Percentage           |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Number of points not covered by any image                    | 689260     | 33.00                |\n",
      "| Number of points covered by less than or equal to 1 image    | 804538     | 38.52                |\n",
      "| Number of points covered by less than or equal to 3 images   | 1093814    | 52.37                |\n",
      "| Number of points covered by less than or equal to 5 images   | 1391624    | 66.63                |\n"
     ]
    }
   ],
   "source": [
    "smc_solver.find_min_cover()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Estimate memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.memory_calculator import memory_calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+-----------------------+\n",
      "|              Memory Type               |  Memory Required (GB) |\n",
      "+----------------------------------------+-----------------------+\n",
      "|      Segmentation for each image       |     0.00048828125     |\n",
      "| Pixel2point association for each image |      0.0009765625     |\n",
      "| Point2pixel association for each image | 0.0077807605266571045 |\n",
      "|                                        |                       |\n",
      "|      Segmentation for all images       |     0.13916015625     |\n",
      "| Pixel2point association for all images |      0.2783203125     |\n",
      "| Point2pixel association for all images |   2.217516750097275   |\n",
      "|          pc_segmentation_ids           |  0.03890380263328552  |\n",
      "|         pc_segmentation_probs          |  0.03890380263328552  |\n",
      "|          keyimage_association          |   0.5543791875243187  |\n",
      "|                 Total                  |   3.2671840116381645  |\n",
      "+----------------------------------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "# pointcloud file\n",
    "las_file = pointcloud_path\n",
    "# image file sample\n",
    "image_file = os.path.join(photos_folder_path, image_list[0])\n",
    "# number of images\n",
    "num_images = len(image_list)\n",
    "# number of segmentation ids for each point in the point cloud\n",
    "num_segmentation_ids = 5\n",
    "\n",
    "memory_calculator(las_file, image_file, num_images, num_segmentation_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run object registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.object_registration import *\n",
    "from ssfm.post_processing import *\n",
    "\n",
    "keyimage_associations_file_name = 'associations_keyimage.npy'\n",
    "keyimage_yaml_name= 'keyimages.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kubric_1/reconstructions/combined_point_cloud.las\n",
      "../../data/kubric_1/associations\n",
      "../../data/kubric_1/segmentations_filtered\n"
     ]
    }
   ],
   "source": [
    "print(pointcloud_path)\n",
    "print(associations_folder_path)\n",
    "print(segmentations_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 285/285 [05:23<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create object registration\n",
    "obr = ObjectRegistration(pointcloud_path, segmentations_folder_path, associations_folder_path, keyimage_associations_file_name=keyimage_associations_file_name)\n",
    "\n",
    "# Run object registration\n",
    "obr.object_registration(iou_threshold=0.50, save_semantics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_semantics_to_pointcloud(pointcloud_path, semantics_path, save_las_path, remove_small_N, nearest_interpolation=False):\n",
    "    \"\"\"\n",
    "    Add semantics to the point cloud and save it as a .las file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pointcloud_path : str, the path to the .las file\n",
    "    semantics_path : str, the path to the semantics file\n",
    "    save_las_path : str, the path to save the .las file\n",
    "    remove_small_N : int, remove the semantics with numbers smaller than N\n",
    "    nearest_interpolation : False, not to use nearest interpolation to assign semantics to the unlabeled points; positive integer, the number of nearest neighbors to use for nearest interpolation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if pointcloud_path.endswith('.las'):\n",
    "        points, colors = read_las_file(pointcloud_path)\n",
    "    elif pointcloud_path.endswith('.npy'):\n",
    "        points, colors = read_mesh_file(pointcloud_path)\n",
    "        colors = colors * 255\n",
    "\n",
    "    semantics = np.load(semantics_path)\n",
    "\n",
    "    semantics_ids = np.unique(semantics)\n",
    "    N_semantics = len(semantics_ids)\n",
    "\n",
    "    print(\"Before removing small semantics: \")\n",
    "    print('maximum of semantics: ', semantics.max())\n",
    "    print('number of unique semantics: ', N_semantics)\n",
    "\n",
    "    # remove the semantics with numbers smaller than a threshold\n",
    "    for semantics_id in semantics_ids:\n",
    "        if np.sum(semantics == semantics_id) < remove_small_N:\n",
    "            semantics[semantics == semantics_id] = -1\n",
    "\n",
    "    print(\"After removing small semantics: \")\n",
    "    print('number of unique semantics: ', len(np.unique(semantics)))\n",
    "\n",
    "    # construct a .las file\n",
    "    hdr = laspy.LasHeader(version=\"1.2\", point_format=3)\n",
    "    hdr.scale = [0.0001, 0.0001, 0.0001]  # Example scale factor, adjust as needed\n",
    "\n",
    "    # Create a LasData object\n",
    "    las = laspy.LasData(hdr)\n",
    "\n",
    "    # Add points\n",
    "    las.x = points[:, 0]\n",
    "    las.y = points[:, 1]\n",
    "    las.z = points[:, 2]\n",
    "\n",
    "    # Add colors\n",
    "    las.red = colors[:, 0]\n",
    "    las.green = colors[:, 1]\n",
    "    las.blue = colors[:, 2]\n",
    "\n",
    "    # Add semantics\n",
    "    if nearest_interpolation is False:\n",
    "        las.intensity = semantics\n",
    "    else:\n",
    "        # labeled points are the points with semantics >=0; unlabeled points are the points with semantics < 0\n",
    "        labeled_points = points[semantics >= 0]\n",
    "        labeled_semantics = semantics[semantics >= 0]\n",
    "        unlabeled_points = points[semantics < 0]\n",
    "\n",
    "        # construct a KDTree\n",
    "        tree = cKDTree(labeled_points)\n",
    "\n",
    "        # find the N nearest neighbors for the unlabeled points\n",
    "        N = nearest_interpolation\n",
    "        distances, indices = tree.query(unlabeled_points, k=N)\n",
    "        nearest_semantics = labeled_semantics[indices]\n",
    "        # find the most frequent semantics\n",
    "        unlabeled_semantics = np.array([np.argmax(np.bincount(nearest_semantics[i])) for i in range(unlabeled_points.shape[0])])\n",
    "\n",
    "        # combine the labeled and unlabeled semantics\n",
    "        combined_semantics = np.zeros(semantics.shape)\n",
    "        combined_semantics[semantics >= 0] = labeled_semantics\n",
    "        combined_semantics[semantics < 0] = unlabeled_semantics\n",
    "\n",
    "        las.intensity = combined_semantics\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    # Write the LAS file\n",
    "    las.write(save_las_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing small semantics: \n",
      "maximum of semantics:  5256\n",
      "number of unique semantics:  814\n",
      "After removing small semantics: \n",
      "number of unique semantics:  227\n"
     ]
    }
   ],
   "source": [
    "image_id = 284\n",
    "remove_small_N = 500\n",
    "semantics_folder_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}.npy'.format(image_id))\n",
    "save_las_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}.las'.format(image_id))\n",
    "add_semantics_to_pointcloud(pointcloud_path, semantics_folder_path, save_las_path, remove_small_N, nearest_interpolation=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kubric_1/associations/semantics/semantics_284.las\n",
      "number of unique semantics:  226\n",
      "number of semantics with less than 100 points:  0\n"
     ]
    }
   ],
   "source": [
    "print(save_las_path)\n",
    "\n",
    "# read las \n",
    "pc = laspy.read(save_las_path)\n",
    "# get the semantics from the intensity\n",
    "semantics = pc.intensity\n",
    "semantics_ids = np.unique(semantics)\n",
    "print('number of unique semantics: ', len(semantics_ids))\n",
    "# print the number of points for each semantics\n",
    "K = 0\n",
    "for i in semantics_ids:\n",
    "    n = np.sum(semantics == i)\n",
    "    if n < 100:\n",
    "        print('semantics id: ', i, ' number of points: ', n)\n",
    "        K += 1\n",
    "\n",
    "print('number of semantics with less than 100 points: ', K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique semantics:  226\n"
     ]
    }
   ],
   "source": [
    "semantic_pc_file_path = save_las_path\n",
    "post_processing = PostProcessing(semantic_pc_file_path)\n",
    "post_processing.shuffle_semantic_ids()\n",
    "save_las_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}_shuffled.las'.format(image_id))\n",
    "post_processing.save_semantic_pointcloud(save_las_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique semantics in prediction:  226\n",
      "Unique semantics in ground truth:  201\n",
      "AP:  [0.8539823008849557, 0.8451327433628318, 0.8185840707964602, 0.8008849557522124, 0.7876106194690266, 0.7389380530973452, 0.6858407079646017, 0.6061946902654868, 0.3805309734513274, 0.084070796460177]  AR:  [0.9601990049751243, 0.9502487562189055, 0.9203980099502488, 0.900497512437811, 0.8855721393034826, 0.8308457711442786, 0.7711442786069652, 0.681592039800995, 0.42786069651741293, 0.0945273631840796]\n",
      "mAP:  0.6601769911504425  mAR:  0.7422885572139303\n"
     ]
    }
   ],
   "source": [
    "# 500, 500\n",
    "from validation import Validator\n",
    "validator = Validator(\n",
    "        save_las_path,\n",
    "        pointcloud_path,\n",
    "    )\n",
    "\n",
    "results = validator.validate(np.arange(0.5, 1.0, 0.05))\n",
    "mAP = results['AP']\n",
    "mAR = results['AR']\n",
    "print('AP: ', mAP, ' AR: ', mAR)\n",
    "mAP = np.sum(mAP) / len(mAP)\n",
    "mAR = np.sum(mAR) / len(mAR)\n",
    "print('mAP: ', mAP, ' mAR: ', mAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique semantics in prediction:  241\n",
      "Unique semantics in ground truth:  201\n",
      "AP:  [0.8091286307053942, 0.8008298755186722, 0.7759336099585062, 0.7510373443983402, 0.7261410788381742, 0.6804979253112033, 0.6265560165975104, 0.5518672199170125, 0.37344398340248963, 0.08298755186721991]  AR:  [0.9701492537313433, 0.9601990049751243, 0.9303482587064676, 0.900497512437811, 0.8706467661691543, 0.8159203980099502, 0.7512437810945274, 0.6616915422885572, 0.44776119402985076, 0.09950248756218906]\n",
      "mAP:  0.6178423236514522  mAR:  0.7407960199004975\n"
     ]
    }
   ],
   "source": [
    "# 400, 500\n",
    "from validation import Validator\n",
    "validator = Validator(\n",
    "        save_las_path,\n",
    "        pointcloud_path,\n",
    "    )\n",
    "\n",
    "results = validator.validate(np.arange(0.5, 1.0, 0.05))\n",
    "mAP = results['AP']\n",
    "mAR = results['AR']\n",
    "print('AP: ', mAP, ' AR: ', mAR)\n",
    "mAP = np.sum(mAP) / len(mAP)\n",
    "mAR = np.sum(mAR) / len(mAR)\n",
    "print('mAP: ', mAP, ' mAR: ', mAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique semantics in prediction:  241\n",
      "Unique semantics in ground truth:  201\n",
      "AP:  [0.8091286307053942, 0.7966804979253111, 0.7676348547717843, 0.7510373443983402, 0.7261410788381742, 0.6763485477178424, 0.6265560165975104, 0.5518672199170125, 0.3817427385892116, 0.08298755186721991]  AR:  [0.9701492537313433, 0.9552238805970149, 0.9203980099502488, 0.900497512437811, 0.8706467661691543, 0.8109452736318408, 0.7512437810945274, 0.6616915422885572, 0.4577114427860697, 0.09950248756218906]\n",
      "mAP:  0.61701244813278  mAR:  0.7398009950248756\n"
     ]
    }
   ],
   "source": [
    "# 400, 350\n",
    "from validation import Validator\n",
    "validator = Validator(\n",
    "        save_las_path,\n",
    "        pointcloud_path,\n",
    "    )\n",
    "\n",
    "results = validator.validate(np.arange(0.5, 1.0, 0.05))\n",
    "mAP = results['AP']\n",
    "mAR = results['AR']\n",
    "print('AP: ', mAP, ' AR: ', mAR)\n",
    "mAP = np.sum(mAP) / len(mAP)\n",
    "mAR = np.sum(mAR) / len(mAR)\n",
    "print('mAP: ', mAP, ' mAR: ', mAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique semantics in prediction:  226\n",
      "Unique semantics in ground truth:  201\n",
      "AP:  [0.8539823008849557, 0.8407079646017699, 0.8141592920353983, 0.8008849557522124, 0.7876106194690266, 0.7389380530973452, 0.6858407079646017, 0.6061946902654868, 0.3938053097345133, 0.084070796460177]  AR:  [0.9601990049751243, 0.945273631840796, 0.9154228855721394, 0.900497512437811, 0.8855721393034826, 0.8308457711442786, 0.7711442786069652, 0.681592039800995, 0.4427860696517413, 0.0945273631840796]\n",
      "mAP:  0.6606194690265486  mAR:  0.7427860696517412\n"
     ]
    }
   ],
   "source": [
    "# 500, 350\n",
    "from validation import Validator\n",
    "validator = Validator(\n",
    "        save_las_path,\n",
    "        pointcloud_path,\n",
    "    )\n",
    "\n",
    "results = validator.validate(np.arange(0.5, 1.0, 0.05))\n",
    "mAP = results['AP']\n",
    "mAR = results['AR']\n",
    "print('AP: ', mAP, ' AR: ', mAR)\n",
    "mAP = np.sum(mAP) / len(mAP)\n",
    "mAR = np.sum(mAR) / len(mAR)\n",
    "print('mAP: ', mAP, ' mAR: ', mAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique semantics in prediction:  201\n",
      "Unique semantics in ground truth:  201\n",
      "AP:  [0.8706467661691543, 0.8557213930348259, 0.8208955223880597, 0.8059701492537313, 0.8009950248756219, 0.746268656716418, 0.6915422885572139, 0.6119402985074627, 0.40298507462686567, 0.0945273631840796]  AR:  [0.8706467661691543, 0.8557213930348259, 0.8208955223880597, 0.8059701492537313, 0.8009950248756219, 0.746268656716418, 0.6915422885572139, 0.6119402985074627, 0.40298507462686567, 0.0945273631840796]\n",
      "mAP:  0.6701492537313433  mAR:  0.6701492537313433\n"
     ]
    }
   ],
   "source": [
    "# 600, 350\n",
    "from validation import Validator\n",
    "validator = Validator(\n",
    "        save_las_path,\n",
    "        pointcloud_path,\n",
    "    )\n",
    "\n",
    "results = validator.validate(np.arange(0.5, 1.0, 0.05))\n",
    "mAP = results['AP']\n",
    "mAR = results['AR']\n",
    "print('AP: ', mAP, ' AR: ', mAR)\n",
    "mAP = np.sum(mAP) / len(mAP)\n",
    "mAR = np.sum(mAR) / len(mAR)\n",
    "print('mAP: ', mAP, ' mAR: ', mAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
