{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import laspy\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from files import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_intrinsics, distortion_coefficients = read_camera_intrinsics_agisoft(\"../../data/box_canyon_export/camera_intrinsics.xml\")\n",
    "cameras = read_camera_extrinsics_agisoft(\"../../data/box_canyon_export/camera_extrinsics.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.97573017e-01 -7.91932875e-01  1.25494270e-01  4.32761423e+05]\n",
      " [-8.01197553e-01  5.83615771e-01 -1.32193469e-01  3.74973898e+06]\n",
      " [ 3.14479185e-02 -1.79540952e-01 -9.83247718e-01  2.06120200e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "extrinsic_matrix = cameras['G:/zhiang/webodm_box_canyon/mission_2/DJI_0247.JPG']\n",
    "\n",
    "print(extrinsic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_file = \"../../data/box_canyon_export/low_sample.las\"\n",
    "points, colors = read_las_file(las_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the point cloud using the extrinsic matrix\n",
    "points_homogeneous = np.hstack((points, np.ones((len(points), 1))))\n",
    "\n",
    "extrinsic_matrix_inv = np.linalg.inv(extrinsic_matrix)\n",
    "\n",
    "points_transformed = np.matmul(points_homogeneous, extrinsic_matrix_inv.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the points using the intrinsic matrix\n",
    "# Drop the homogeneous component (w)\n",
    "points_camera_space = points_transformed[:, :3]\n",
    "\n",
    "# save the points to las file with colors\n",
    "las = laspy.create(file_version=\"1.2\", point_format=3)\n",
    "las.x = points_camera_space[:, 0]\n",
    "las.y = points_camera_space[:, 1]\n",
    "las.z = points_camera_space[:, 2]\n",
    "las.red = colors[:, 0]\n",
    "las.green = colors[:, 1]\n",
    "las.blue = colors[:, 2]\n",
    "#las.intensity = colors[:, 3]   # intensity is used to store the alpha channel\n",
    "las.write(\"../../data/box_canyon_export/low_sample_transformed.las\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.55628665e+03 0.00000000e+00 2.73600000e+03]\n",
      " [0.00000000e+00 3.55628665e+03 1.82400000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "(5919332, 3)\n",
      "[[3.55628665e+03 0.00000000e+00 2.73600000e+03]\n",
      " [0.00000000e+00 2.36537000e+03 1.82400000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(camera_intrinsics)\n",
    "print(points_camera_space.shape)\n",
    "camera_intrinsics[0, 2] = 5472/2\n",
    "camera_intrinsics[1, 2] = 3648/2\n",
    "camera_intrinsics[1, 1] = 2365.37\n",
    "print(camera_intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3648 5472\n"
     ]
    }
   ],
   "source": [
    "points_projected = np.matmul(points_camera_space, camera_intrinsics.T)\n",
    "points_projected /= points_projected[:, -1].reshape(-1, 1)\n",
    "\n",
    "image_height = cameras['height']\n",
    "image_width = cameras['width']\n",
    "\n",
    "print(image_height, image_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image (2D array) and z-buffer\n",
    "image = np.zeros((image_height, image_width, 3), dtype=np.uint8)\n",
    "z_buffer = np.full((image_height, image_width), np.inf)\n",
    "associations = {}\n",
    "\n",
    "points_flags = []\n",
    "# Iterate through each point\n",
    "for point, color in zip(points_projected, colors):\n",
    "    x, y, z = point[:3]\n",
    "\n",
    "    # Convert to pixel coordinates\n",
    "    px, py = int(x), int(y)\n",
    "\n",
    "    # Check if the point is within the image bounds\n",
    "    if 0 <= px < image_width and 0 <= py < image_height:\n",
    "        # Update the pixel if this point is closer to the camera\n",
    "        if z < z_buffer[py, px]:\n",
    "            z_buffer[py, px] = z\n",
    "            image[py, px] = (np.array(color) / 255).astype(np.uint8)\n",
    "\n",
    "        points_flags.append(True)\n",
    "\n",
    "    else:\n",
    "        points_flags.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_points = points_camera_space[points_flags]\n",
    "filtered_colors = colors[points_flags]\n",
    "\n",
    "# save filtered points to las file\n",
    "las = laspy.create(file_version=\"1.2\", point_format=3)\n",
    "las.x = filtered_points[:, 0]\n",
    "las.y = filtered_points[:, 1]\n",
    "las.z = filtered_points[:, 2]\n",
    "las.red = filtered_colors[:, 0]\n",
    "las.green = filtered_colors[:, 1]\n",
    "las.blue = filtered_colors[:, 2]\n",
    "#las.intensity = colors[:, 3]   # intensity is used to store the alpha channel\n",
    "las.write(\"../../data/box_canyon_export/low_sample_transformed_projected.las\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the image\n",
    "cv2.imwrite(\"../../data/box_canyon_export/low_sample_transformed.png\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
