{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic SfM: single scene on synthetic data generated from Kubric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Generate synthetic data\n",
    "We developed a tool to generate synthetic data using Kubric. Please follow the instructions on the Github repo: https://github.com/ZhiangChen/data_generator_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Organize data\n",
    "Create a folder under `semantic_SfM/data` and organize your data following the structures below. \n",
    "\n",
    "```\n",
    "semantic_SfM/data\n",
    "    ├── kubric_0\n",
    "        ├── photos\n",
    "        │       ├── 0.png\n",
    "        │       ├── 1.png\n",
    "        │       ├── ...\n",
    "        │       └── 323.png\n",
    "        ├── reconstructions\n",
    "        │       ├── camera_poses.npy\n",
    "        │       └── combined_point_cloud.las   \n",
    "        ├── segmentations_gt\n",
    "        │       ├── 0.npy\n",
    "        │       ├── 0.png\n",
    "        │       └── ...\n",
    "        └── associations\n",
    "                └── depth\n",
    "                        ├── 0.npy\n",
    "                        ├── 0.png\n",
    "                        └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "scene_dir = '../../data/kubric_0'\n",
    "pointcloud_path = os.path.join(scene_dir, 'reconstructions', 'combined_point_cloud.las')\n",
    "associations_folder_path = os.path.join(scene_dir, 'associations')\n",
    "segmentations_folder_path = os.path.join(scene_dir, 'segmentations')\n",
    "photos_folder_path = os.path.join(scene_dir, 'photos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Segment images using SAM \n",
    "\n",
    "#### 2a. SAM segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.image_segmentation import ImageSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_params = {}\n",
    "sam_params['model_name'] = 'sam2'\n",
    "sam_params['model_path'] = '../../semantic_SfM/sam2/sam2.1_hiera_large.pt'\n",
    "sam_params['device'] = 'cuda:1'\n",
    "sam_params['points_per_side'] = 32\n",
    "sam_params['points_per_batch'] = 128\n",
    "sam_params['pred_iou_thresh'] = 0.6\n",
    "sam_params['stability_score_offset'] = 0.5\n",
    "sam_params['box_nms_thresh'] = 0.6\n",
    "sam_params['use_m2m'] = True\n",
    "\n",
    "\n",
    "image_paths = [os.path.join(scene_dir, 'photos', image) for image in os.listdir(os.path.join(scene_dir, 'photos'))]\n",
    "\n",
    "# sort images based on the values of keyimages in file names\n",
    "image_paths = sorted(image_paths, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/285.\n",
      "Processing image 2/285.\n",
      "Processing image 3/285.\n",
      "Processing image 4/285.\n",
      "Processing image 5/285.\n",
      "Processing image 6/285.\n",
      "Processing image 7/285.\n",
      "Processing image 8/285.\n",
      "Processing image 9/285.\n",
      "Processing image 10/285.\n",
      "Processing image 11/285.\n",
      "Processing image 12/285.\n",
      "Processing image 13/285.\n",
      "Processing image 14/285.\n",
      "Processing image 15/285.\n",
      "Processing image 16/285.\n",
      "Processing image 17/285.\n",
      "Processing image 18/285.\n",
      "Processing image 19/285.\n",
      "Processing image 20/285.\n",
      "Processing image 21/285.\n",
      "Processing image 22/285.\n",
      "Processing image 23/285.\n",
      "Processing image 24/285.\n",
      "Processing image 25/285.\n",
      "Processing image 26/285.\n",
      "Processing image 27/285.\n",
      "Processing image 28/285.\n",
      "Processing image 29/285.\n",
      "Processing image 30/285.\n",
      "Processing image 31/285.\n",
      "Processing image 32/285.\n",
      "Processing image 33/285.\n",
      "Processing image 34/285.\n",
      "Processing image 35/285.\n",
      "Processing image 36/285.\n",
      "Processing image 37/285.\n",
      "Processing image 38/285.\n",
      "Processing image 39/285.\n",
      "Processing image 40/285.\n",
      "Processing image 41/285.\n",
      "Processing image 42/285.\n",
      "Processing image 43/285.\n",
      "Processing image 44/285.\n",
      "Processing image 45/285.\n",
      "Processing image 46/285.\n",
      "Processing image 47/285.\n",
      "Processing image 48/285.\n",
      "Processing image 49/285.\n",
      "Processing image 50/285.\n",
      "Processing image 51/285.\n",
      "Processing image 52/285.\n",
      "Processing image 53/285.\n",
      "Processing image 54/285.\n",
      "Processing image 55/285.\n",
      "Processing image 56/285.\n",
      "Processing image 57/285.\n",
      "Processing image 58/285.\n",
      "Processing image 59/285.\n",
      "Processing image 60/285.\n",
      "Processing image 61/285.\n",
      "Processing image 62/285.\n",
      "Processing image 63/285.\n",
      "Processing image 64/285.\n",
      "Processing image 65/285.\n",
      "Processing image 66/285.\n",
      "Processing image 67/285.\n",
      "Processing image 68/285.\n",
      "Processing image 69/285.\n",
      "Processing image 70/285.\n",
      "Processing image 71/285.\n",
      "Processing image 72/285.\n",
      "Processing image 73/285.\n",
      "Processing image 74/285.\n",
      "Processing image 75/285.\n",
      "Processing image 76/285.\n",
      "Processing image 77/285.\n",
      "Processing image 78/285.\n",
      "Processing image 79/285.\n",
      "Processing image 80/285.\n",
      "Processing image 81/285.\n",
      "Processing image 82/285.\n",
      "Processing image 83/285.\n",
      "Processing image 84/285.\n",
      "Processing image 85/285.\n",
      "Processing image 86/285.\n",
      "Processing image 87/285.\n",
      "Processing image 88/285.\n",
      "Processing image 89/285.\n",
      "Processing image 90/285.\n",
      "Processing image 91/285.\n",
      "Processing image 92/285.\n",
      "Processing image 93/285.\n",
      "Processing image 94/285.\n",
      "Processing image 95/285.\n",
      "Processing image 96/285.\n",
      "Processing image 97/285.\n",
      "Processing image 98/285.\n",
      "Processing image 99/285.\n",
      "Processing image 100/285.\n",
      "Processing image 101/285.\n",
      "Processing image 102/285.\n",
      "Processing image 103/285.\n",
      "Processing image 104/285.\n",
      "Processing image 105/285.\n",
      "Processing image 106/285.\n",
      "Processing image 107/285.\n",
      "Processing image 108/285.\n",
      "Processing image 109/285.\n",
      "Processing image 110/285.\n",
      "Processing image 111/285.\n",
      "Processing image 112/285.\n",
      "Processing image 113/285.\n",
      "Processing image 114/285.\n",
      "Processing image 115/285.\n",
      "Processing image 116/285.\n",
      "Processing image 117/285.\n",
      "Processing image 118/285.\n",
      "Processing image 119/285.\n",
      "Processing image 120/285.\n",
      "Processing image 121/285.\n",
      "Processing image 122/285.\n",
      "Processing image 123/285.\n",
      "Processing image 124/285.\n",
      "Processing image 125/285.\n",
      "Processing image 126/285.\n",
      "Processing image 127/285.\n",
      "Processing image 128/285.\n",
      "Processing image 129/285.\n",
      "Processing image 130/285.\n",
      "Processing image 131/285.\n",
      "Processing image 132/285.\n",
      "Processing image 133/285.\n",
      "Processing image 134/285.\n",
      "Processing image 135/285.\n",
      "Processing image 136/285.\n",
      "Processing image 137/285.\n",
      "Processing image 138/285.\n",
      "Processing image 139/285.\n",
      "Processing image 140/285.\n",
      "Processing image 141/285.\n",
      "Processing image 142/285.\n",
      "Processing image 143/285.\n",
      "Processing image 144/285.\n",
      "Processing image 145/285.\n",
      "Processing image 146/285.\n",
      "Processing image 147/285.\n",
      "Processing image 148/285.\n",
      "Processing image 149/285.\n",
      "Processing image 150/285.\n",
      "Processing image 151/285.\n",
      "Processing image 152/285.\n",
      "Processing image 153/285.\n",
      "Processing image 154/285.\n",
      "Processing image 155/285.\n",
      "Processing image 156/285.\n",
      "Processing image 157/285.\n",
      "Processing image 158/285.\n",
      "Processing image 159/285.\n",
      "Processing image 160/285.\n",
      "Processing image 161/285.\n",
      "Processing image 162/285.\n",
      "Processing image 163/285.\n",
      "Processing image 164/285.\n",
      "Processing image 165/285.\n",
      "Processing image 166/285.\n",
      "Processing image 167/285.\n",
      "Processing image 168/285.\n",
      "Processing image 169/285.\n",
      "Processing image 170/285.\n",
      "Processing image 171/285.\n",
      "Processing image 172/285.\n",
      "Processing image 173/285.\n",
      "Processing image 174/285.\n",
      "Processing image 175/285.\n",
      "Processing image 176/285.\n",
      "Processing image 177/285.\n",
      "Processing image 178/285.\n",
      "Processing image 179/285.\n",
      "Processing image 180/285.\n",
      "Processing image 181/285.\n",
      "Processing image 182/285.\n",
      "Processing image 183/285.\n",
      "Processing image 184/285.\n",
      "Processing image 185/285.\n",
      "Processing image 186/285.\n",
      "Processing image 187/285.\n",
      "Processing image 188/285.\n",
      "Processing image 189/285.\n",
      "Processing image 190/285.\n",
      "Processing image 191/285.\n",
      "Processing image 192/285.\n",
      "Processing image 193/285.\n",
      "Processing image 194/285.\n",
      "Processing image 195/285.\n",
      "Processing image 196/285.\n",
      "Processing image 197/285.\n",
      "Processing image 198/285.\n",
      "Processing image 199/285.\n",
      "Processing image 200/285.\n",
      "Processing image 201/285.\n",
      "Processing image 202/285.\n",
      "Processing image 203/285.\n",
      "Processing image 204/285.\n",
      "Processing image 205/285.\n",
      "Processing image 206/285.\n",
      "Processing image 207/285.\n",
      "Processing image 208/285.\n",
      "Processing image 209/285.\n",
      "Processing image 210/285.\n",
      "Processing image 211/285.\n",
      "Processing image 212/285.\n",
      "Processing image 213/285.\n",
      "Processing image 214/285.\n",
      "Processing image 215/285.\n",
      "Processing image 216/285.\n",
      "Processing image 217/285.\n",
      "Processing image 218/285.\n",
      "Processing image 219/285.\n",
      "Processing image 220/285.\n",
      "Processing image 221/285.\n",
      "Processing image 222/285.\n",
      "Processing image 223/285.\n",
      "Processing image 224/285.\n",
      "Processing image 225/285.\n",
      "Processing image 226/285.\n",
      "Processing image 227/285.\n",
      "Processing image 228/285.\n",
      "Processing image 229/285.\n",
      "Processing image 230/285.\n",
      "Processing image 231/285.\n",
      "Processing image 232/285.\n",
      "Processing image 233/285.\n",
      "Processing image 234/285.\n",
      "Processing image 235/285.\n",
      "Processing image 236/285.\n",
      "Processing image 237/285.\n",
      "Processing image 238/285.\n",
      "Processing image 239/285.\n",
      "Processing image 240/285.\n",
      "Processing image 241/285.\n",
      "Processing image 242/285.\n",
      "Processing image 243/285.\n",
      "Processing image 244/285.\n",
      "Processing image 245/285.\n",
      "Processing image 246/285.\n",
      "Processing image 247/285.\n",
      "Processing image 248/285.\n",
      "Processing image 249/285.\n",
      "Processing image 250/285.\n",
      "Processing image 251/285.\n",
      "Processing image 252/285.\n",
      "Processing image 253/285.\n",
      "Processing image 254/285.\n",
      "Processing image 255/285.\n",
      "Processing image 256/285.\n",
      "Processing image 257/285.\n",
      "Processing image 258/285.\n",
      "Processing image 259/285.\n",
      "Processing image 260/285.\n",
      "Processing image 261/285.\n",
      "Processing image 262/285.\n",
      "Processing image 263/285.\n",
      "Processing image 264/285.\n",
      "Processing image 265/285.\n",
      "Processing image 266/285.\n",
      "Processing image 267/285.\n",
      "Processing image 268/285.\n",
      "Processing image 269/285.\n",
      "Processing image 270/285.\n",
      "Processing image 271/285.\n",
      "Processing image 272/285.\n",
      "Processing image 273/285.\n",
      "Processing image 274/285.\n",
      "Processing image 275/285.\n",
      "Processing image 276/285.\n",
      "Processing image 277/285.\n",
      "Processing image 278/285.\n",
      "Processing image 279/285.\n",
      "Processing image 280/285.\n",
      "Processing image 281/285.\n",
      "Processing image 282/285.\n",
      "Processing image 283/285.\n",
      "Processing image 284/285.\n",
      "Processing image 285/285.\n"
     ]
    }
   ],
   "source": [
    "run_segmentation = False\n",
    "\n",
    "if run_segmentation:\n",
    "    image_segmentor = ImageSegmentation(sam_params)   \n",
    "    image_segmentor.batch_predict(image_paths, segmentations_folder_path, save_overlap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Mask filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.simple_mask_filter import AreaFilter\n",
    "area_filter = AreaFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:05<00:00, 52.50it/s]\n"
     ]
    }
   ],
   "source": [
    "segmentations_folder_path = os.path.join(scene_dir, 'segmentations_filtered')\n",
    "\n",
    "config = {'area_lower_threshold': 100,\n",
    "'segmentation_folder_path': '../../data/kubric_0/segmentations',\n",
    "'output_folder_path': segmentations_folder_path,\n",
    "'num_processes':8}\n",
    "\n",
    "area_filter(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create projection associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.probabilistic_projection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud_projector = PointcloudProjection(depth_filtering_threshold=1.8)\n",
    "pointcloud_projector.read_kubric_camera_parameters(scene_dir)\n",
    "pointcloud_projector.read_pointcloud(pointcloud_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image list\n",
    "photo_folder_path = os.path.join(scene_dir, 'photos')\n",
    "image_list = [f for f in os.listdir(photo_folder_path) if f.endswith('.png')]\n",
    "# sort image list based on the number in the file name\n",
    "image_list.sort(key=lambda x: int(x.split('/')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 285/285 [00:13<00:00, 20.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#pointcloud_projector.parallel_batch_project(image_list, save_folder_path)\n",
    "pointcloud_projector.parallel_batch_project_joblib(image_list, associations_folder_path, num_workers=16, save_depth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keyimage associations\n",
    "from ssfm.keyimage_associations_builder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kubric_0/associations\n",
      "../../data/kubric_0/segmentations_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:01<00:00, 211.60it/s]\n"
     ]
    }
   ],
   "source": [
    "print(associations_folder_path)\n",
    "print(segmentations_folder_path)\n",
    "smc_solver = KeyimageAssociationsBuilder(image_list, associations_folder_path, segmentations_folder_path)\n",
    "smc_solver.build_associations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric                                                       | Count      | Percentage           |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Number of points not covered by any image                    | 687711     | 32.23                |\n",
      "| Number of points covered by less than or equal to 1 image    | 802259     | 37.59                |\n",
      "| Number of points covered by less than or equal to 3 images   | 1098365    | 51.47                |\n",
      "| Number of points covered by less than or equal to 5 images   | 1406791    | 65.92                |\n"
     ]
    }
   ],
   "source": [
    "smc_solver.find_min_cover()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Estimate memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.memory_calculator import memory_calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------+\n",
      "|              Memory Type               | Memory Required (GB) |\n",
      "+----------------------------------------+----------------------+\n",
      "|      Segmentation for each image       |    0.00048828125     |\n",
      "| Pixel2point association for each image |     0.0009765625     |\n",
      "| Point2pixel association for each image | 0.007866773754358292 |\n",
      "|                                        |                      |\n",
      "|      Segmentation for all images       |    0.13916015625     |\n",
      "| Pixel2point association for all images |     0.2783203125     |\n",
      "| Point2pixel association for all images |  2.242030519992113   |\n",
      "|          pc_segmentation_ids           | 0.03933386877179146  |\n",
      "|         pc_segmentation_probs          | 0.03933386877179146  |\n",
      "|          keyimage_association          |  0.5605076299980283  |\n",
      "|                 Total                  |  3.2986863562837243  |\n",
      "+----------------------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "# pointcloud file\n",
    "las_file = pointcloud_path\n",
    "# image file sample\n",
    "image_file = os.path.join(photos_folder_path, image_list[0])\n",
    "# number of images\n",
    "num_images = len(image_list)\n",
    "# number of segmentation ids for each point in the point cloud\n",
    "num_segmentation_ids = 5\n",
    "\n",
    "memory_calculator(las_file, image_file, num_images, num_segmentation_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run object registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.object_registration import *\n",
    "from ssfm.post_processing import *\n",
    "\n",
    "keyimage_associations_file_name = 'associations_keyimage.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kubric_0/reconstructions/combined_point_cloud.las\n",
      "../../data/kubric_0/associations\n",
      "../../data/kubric_0/segmentations_filtered\n"
     ]
    }
   ],
   "source": [
    "print(pointcloud_path)\n",
    "print(associations_folder_path)\n",
    "print(segmentations_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 285/285 [04:52<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create object registration\n",
    "obr = ObjectRegistration(pointcloud_path, segmentations_folder_path, associations_folder_path, keyimage_associations_file_name=keyimage_associations_file_name, image_list=image_list)\n",
    "\n",
    "# Run object registration\n",
    "obr.object_registration(iou_threshold=0.2, save_semantics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing small semantics: \n",
      "maximum of semantics:  5080\n",
      "number of unique semantics:  534\n",
      "After removing small semantics: \n",
      "number of unique semantics:  207\n"
     ]
    }
   ],
   "source": [
    "image_id = 284\n",
    "semantics_folder_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}.npy'.format(image_id))\n",
    "save_las_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}.las'.format(image_id))\n",
    "add_semantics_to_pointcloud(pointcloud_path, semantics_folder_path, save_las_path, remove_small_N=500, nearest_interpolation=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kubric_0/associations/semantics/semantics_284.las\n",
      "number of unique semantics:  206\n",
      "number of semantics with less than 100 points:  0\n"
     ]
    }
   ],
   "source": [
    "print(save_las_path)\n",
    "\n",
    "# read las \n",
    "pc = laspy.read(save_las_path)\n",
    "# get the semantics from the intensity\n",
    "semantics = pc.intensity\n",
    "semantics_ids = np.unique(semantics)\n",
    "print('number of unique semantics: ', len(semantics_ids))\n",
    "# print the number of points for each semantics\n",
    "K = 0\n",
    "for i in semantics_ids:\n",
    "    n = np.sum(semantics == i)\n",
    "    if n < 100:\n",
    "        print('semantics id: ', i, ' number of points: ', n)\n",
    "        K += 1\n",
    "\n",
    "print('number of semantics with less than 100 points: ', K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique semantics:  206\n"
     ]
    }
   ],
   "source": [
    "semantic_pc_file_path = save_las_path\n",
    "post_processing = PostProcessing(semantic_pc_file_path)\n",
    "post_processing.shuffle_semantic_ids()\n",
    "save_las_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}_shuffled.las'.format(image_id))\n",
    "post_processing.save_semantic_pointcloud(save_las_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique semantics in prediction:  206\n",
      "Unique semantics in ground truth:  201\n",
      "AP:  [0.9271844660194175, 0.912621359223301, 0.9077669902912622, 0.9029126213592233, 0.8737864077669902, 0.8543689320388349, 0.8106796116504854, 0.7815533980582524, 0.6553398058252428, 0.35436893203883496]  AR:  [0.9502487562189055, 0.9353233830845771, 0.9303482587064676, 0.9253731343283582, 0.8955223880597015, 0.8756218905472637, 0.8308457711442786, 0.8009950248756219, 0.6716417910447762, 0.36318407960199006]\n",
      "mAP:  0.7980582524271844  mAR:  0.817910447761194\n"
     ]
    }
   ],
   "source": [
    "# 500, 500\n",
    "from validation import Validator\n",
    "validator = Validator(\n",
    "        save_las_path,\n",
    "        pointcloud_path,\n",
    "    )\n",
    "\n",
    "results = validator.validate(np.arange(0.5, 1.0, 0.05))\n",
    "mAP = results['AP']\n",
    "mAR = results['AR']\n",
    "print('AP: ', mAP, ' AR: ', mAR)\n",
    "mAP = np.sum(mAP) / len(mAP)\n",
    "mAR = np.sum(mAR) / len(mAR)\n",
    "print('mAP: ', mAP, ' mAR: ', mAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
