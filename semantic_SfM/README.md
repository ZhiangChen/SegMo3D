# SegMo3D: Large-scale 3D Semantic Mapping Using Structure-from-Motion and Segmentation Mosaicking Algorithms
We present a methodology to address challenges in large-scale 3D semantic mapping. Using overlapping images collected over environments of interest, Structure-from-Motion (SfM) produces georeferenced point clouds and estimates camera poses. Existing large vision models (LVMs) such as Segment Anything Model segment instances in the images. To achieve 3D segmentation in the point clouds, we project the points back onto the camera image planes, aligning points with the corresponding 2D segmentation. As instances are independently segmented across multiple images with different perspectives, we develop a segmentation mosaicking algorithm to associate and mosaick instances from key images in a weighted undirected graph. Our methodology is validated using both synthetic data generated by Kubric and real-world UAV-SfM data. By leveraging LVMs, our approach eliminates the need for 2D or 3D training data. Additionally, by integrating Grounding DINO, the method supports segmentation of objects of interest using text prompts, enhancing its flexibility and adaptability to varied tasks. Designed to be compatible with existing SfM software, including Agisoft and OpenDroneMap, our implementation integrates into established large-scale mapping workflow.


![workflow](./docs/images/workflow_wide.jpg)


![depth_filtering_result](./docs/images/depth_filtering.png)


## Installation 
```
git clone https://github.com/ZhiangChen/SegMo3D.git
cd SegMo3D/semantic_SfM/ssfm/
pip3 install .
```



**Hardware requirements**: This project utilizes the Segment Anything Model (SAM) for panoptic segmentation. GPUs are not required for SAM but are recommended to expedite inference speed. The other parts of this project use only CPUs. As a point cloud will be stored in memory, memory usage depends on the point cloud size. 

## SegMo3D Architecture
[files.py](./semantic_SfM/ssfm/files.py) provides utility functions for file operation, such as point cloud and image files.

[image_segmentation.py](./semantic_SfM/ssfm/image_segmentation.py) allows to select deep learning models for instance segmentation and panoptic segmentation. (**Pixel-segmentation association**)

[probabilistic_projection.py](./semantic_SfM/ssfm/probabilistic_projection.py) projects point clouds to images and creates a probablistic semantics. (**Pixel-point association**)

[object_registration.py](./semantic_SfM/ssfm/object_registration.py) registers objects (instances and stuffs) in point clouds. (**Point-segmentation association**/**Segmentation mosaicking**)

[post_processing.py](./semantic_SfM/ssfm/post_processing.py) provides methods to clean and post process the segmented 3D point clouds. 


## Support Platforms and Models
This repository supports SfM products from the following platforms: 
- [WebODM](https://opendronemap.org/webodm/)
- [Agisoft](https://www.agisoft.com/)

Refer to the [docs/projection_tutorial.md](docs/projection_tutorial.md) to obtain point clouds and camera parameters from WebODM or Agisoft. The point clouds should use the format of [.las](https://laspy.readthedocs.io/en/latest/intro.html). 

For image segmentation, we have used SAM/SAM2 and Grounding DINO: 
- [SAM](https://github.com/facebookresearch/segment-anything)
- [SAM2](https://github.com/facebookresearch/sam2)
- [Grounding DINO](http://github.com/IDEA-Research/GroundingDINO)


## Tutorials
1. Projecting Point Clouds onto Image Planes: [docs/projection_tutorial.md](docs/projection_tutorial.md)

2. Camera Calibration in SfM: [docs/camera_calibration_optimization.md](docs/camera_calibration_optimization.md)

3. Depth Filtering: [docs/depth_filtering.md](docs/depth_filtering.md)

4. Data Structure and Algorithms for Object Registration/Point-segmentation association: [docs/object_registration.md](docs/object_registration.md)


5. Running a Complete Workflow Example from Scratch: [semantic_SfM/ssfm/workflow.ipynb](semantic_SfM/ssfm/workflow.ipynb)