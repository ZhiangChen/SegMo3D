{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic SfM: single scene on synthetic data generated from Kubric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Generate synthetic data\n",
    "We developed a tool to generate synthetic data using Kubric. Please follow the instructions on the Github repo: https://github.com/ZhiangChen/data_generator_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Organize data\n",
    "Create a folder under `semantic_SfM/data` and organize your data following the structures below. \n",
    "\n",
    "```\n",
    "semantic_SfM/data\n",
    "    ├── kubric_0\n",
    "        ├── photos\n",
    "        │       ├── 0.png\n",
    "        │       ├── 1.png\n",
    "        │       ├── ...\n",
    "        │       └── 323.png\n",
    "        ├── reconstructions\n",
    "        │       ├── camera_poses.npy\n",
    "        │       └── combined_point_cloud.las   \n",
    "        ├── segmentations_gt\n",
    "        │       ├── 0.npy\n",
    "        │       ├── 0.png\n",
    "        │       └── ...\n",
    "        └── associations\n",
    "                └── depth\n",
    "                        ├── 0.npy\n",
    "                        ├── 0.png\n",
    "                        └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Segment images using SAM \n",
    "\n",
    "#### 2a. SAM segmentation (skipped)\n",
    "\n",
    "#### 2b. Mask filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.simple_mask_filter import AreaFilter\n",
    "area_filter = AreaFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:05<00:00, 52.37it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {'area_lower_threshold': 100,\n",
    "'segmentation_folder_path': '../../data/kubric_1/segmentations_gt',\n",
    "'output_folder_path': '../../data/kubric_1/segmentations_gt_filtered',\n",
    "'num_processes':8}\n",
    "\n",
    "area_filter(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create projection associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.probabilistic_projection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "scene_dir = '../../data/kubric_0'\n",
    "pointcloud_path = os.path.join(scene_dir, 'reconstructions', 'combined_point_cloud.las')\n",
    "associations_folder_path = os.path.join(scene_dir, 'associations')\n",
    "segmentations_folder_path = os.path.join(scene_dir, 'segmentations_gt_filtered')\n",
    "photos_folder_path = os.path.join(scene_dir, 'photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud_projector = PointcloudProjection(depth_filtering_threshold=1.8)\n",
    "pointcloud_projector.read_kubric_camera_parameters(scene_dir)\n",
    "pointcloud_projector.read_pointcloud(pointcloud_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image list\n",
    "photo_folder_path = os.path.join(scene_dir, 'photos')\n",
    "image_list = [f for f in os.listdir(photo_folder_path) if f.endswith('.png')]\n",
    "# sort image list based on the number in the file name\n",
    "image_list.sort(key=lambda x: int(x.split('/')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 285/285 [00:16<00:00, 17.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#pointcloud_projector.parallel_batch_project(image_list, save_folder_path)\n",
    "pointcloud_projector.parallel_batch_project_joblib(image_list, associations_folder_path, num_workers=16, save_depth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keyimage associations\n",
    "from ssfm.keyimage_associations_builder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smc_solver = KeyimageAssociationsBuilder(image_list, associations_folder_path, segmentations_folder_path)\n",
    "smc_solver.build_associations()\n",
    "smc_solver.build_graph(num_chunks=10)\n",
    "\n",
    "smc_solver.add_camera_to_graph([scene_dir], camera_type=\"Kubric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric                                                       | Count      | Percentage           |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Number of points not covered by any image                    | 677264     | 32.07                |\n",
      "| Number of points covered by less than or equal to 1 image    | 777788     | 36.83                |\n",
      "| Number of points covered by less than or equal to 3 images   | 1041895    | 49.34                |\n",
      "| Number of points covered by less than or equal to 5 images   | 1330600    | 63.01                |\n"
     ]
    }
   ],
   "source": [
    "smc_solver.find_min_cover()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Estimate memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.memory_calculator import memory_calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------+\n",
      "|              Memory Type               | Memory Required (GB) |\n",
      "+----------------------------------------+----------------------+\n",
      "|      Segmentation for each image       |    0.00048828125     |\n",
      "| Pixel2point association for each image |     0.0009765625     |\n",
      "| Point2pixel association for each image | 0.007866773754358292 |\n",
      "|                                        |                      |\n",
      "|      Segmentation for all images       |    0.13916015625     |\n",
      "| Pixel2point association for all images |     0.2783203125     |\n",
      "| Point2pixel association for all images |  2.242030519992113   |\n",
      "|          pc_segmentation_ids           | 0.03933386877179146  |\n",
      "|         pc_segmentation_probs          | 0.03933386877179146  |\n",
      "|          keyimage_association          |  0.5605076299980283  |\n",
      "|                 Total                  |  3.2986863562837243  |\n",
      "+----------------------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "# pointcloud file\n",
    "las_file = pointcloud_path\n",
    "# image file sample\n",
    "image_file = os.path.join(photos_folder_path, image_list[0])\n",
    "# number of images\n",
    "num_images = len(image_list)\n",
    "# number of segmentation ids for each point in the point cloud\n",
    "num_segmentation_ids = 5\n",
    "\n",
    "memory_calculator(las_file, image_file, num_images, num_segmentation_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run object registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssfm.object_registration import *\n",
    "from ssfm.post_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kubric_1/reconstructions/combined_point_cloud.las\n",
      "../../data/kubric_1/associations\n",
      "../../data/kubric_1/segmentations_gt_filtered\n"
     ]
    }
   ],
   "source": [
    "print(pointcloud_path)\n",
    "print(associations_folder_path)\n",
    "print(segmentations_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 285/285 [02:35<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create object registration\n",
    "obr = ObjectRegistration(pointcloud_path, segmentations_folder_path, associations_folder_path, image_list=image_list, using_graph=True)\n",
    "\n",
    "# Run object registration\n",
    "obr.object_registration(iou_threshold=0.50, save_semantics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing small semantics: \n",
      "maximum of semantics:  2591\n",
      "number of unique semantics:  202\n",
      "After removing small semantics: \n",
      "number of unique semantics:  202\n"
     ]
    }
   ],
   "source": [
    "image_id = 284\n",
    "semantics_folder_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}.npy'.format(image_id))\n",
    "save_las_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}.las'.format(image_id))\n",
    "add_semantics_to_pointcloud(pointcloud_path, semantics_folder_path, save_las_path, nearest_interpolation=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kubric_1/associations/semantics/semantics_284.las\n",
      "number of unique semantics:  201\n"
     ]
    }
   ],
   "source": [
    "print(save_las_path)\n",
    "\n",
    "# read las \n",
    "pc = laspy.read(save_las_path)\n",
    "# get the semantics from the intensity\n",
    "semantics = pc.intensity\n",
    "semantics_ids = np.unique(semantics)\n",
    "print('number of unique semantics: ', len(semantics_ids))\n",
    "# print the number of points for each semantics\n",
    "for i in semantics_ids:\n",
    "    n = np.sum(semantics == i)\n",
    "    if n < 100:\n",
    "        print('semantics id: ', i, ' number of points: ', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique semantics:  201\n"
     ]
    }
   ],
   "source": [
    "semantic_pc_file_path = save_las_path\n",
    "post_processing = PostProcessing(semantic_pc_file_path)\n",
    "post_processing.shuffle_semantic_ids(exclude_largest_semantic=True)\n",
    "save_las_path = os.path.join(associations_folder_path, 'semantics', 'semantics_{}_shuffled.las'.format(image_id))\n",
    "post_processing.save_semantic_pointcloud(save_las_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique semantics in prediction:  201\n",
      "Unique semantics in ground truth:  201\n",
      "mAP:  0.8432835820895523  mAR:  0.8432835820895523\n"
     ]
    }
   ],
   "source": [
    "from validation import Validator\n",
    "validator = Validator(\n",
    "        save_las_path,\n",
    "        pointcloud_path,\n",
    "    )\n",
    "\n",
    "results = validator.validate(np.arange(0.5, 1.0, 0.05))\n",
    "mAP = results['AP']\n",
    "mAR = results['AR']\n",
    "\n",
    "mAP = np.sum(mAP) / len(mAP)\n",
    "mAR = np.sum(mAR) / len(mAR)\n",
    "print('mAP: ', mAP, ' mAR: ', mAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP, mAR = ([0.9950248756218906,\n",
    "  0.9900497512437811,\n",
    "  0.9850746268656716,\n",
    "  0.9751243781094527,\n",
    "  0.945273631840796,\n",
    "  0.8606965174129353,\n",
    "  0.6716417910447762,\n",
    "  0.43781094527363185,\n",
    "  0.263681592039801,\n",
    "  0.04477611940298507],\n",
    " [0.9950248756218906,\n",
    "  0.9900497512437811,\n",
    "  0.9850746268656716,\n",
    "  0.9751243781094527,\n",
    "  0.945273631840796,\n",
    "  0.8606965174129353,\n",
    "  0.6716417910447762,\n",
    "  0.43781094527363185,\n",
    "  0.263681592039801,\n",
    "  0.04477611940298507])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
